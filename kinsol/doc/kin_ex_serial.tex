%===============================================================================
\section{Serial example problems}\label{s:ex_serial}
%===============================================================================

\subsection{A Krylov example: \id{kinwebs}}\label{ss:kinwebs}

We give here an example that illustrates the use of {\kinsol} with the Krylov
method {\spgmr}, in the {\kinspgmr} module, as the linear system solver.
The source file, \id{kinwebs.c}, is listed in Appendix \ref{s:kinwebs_c}.

This program solves a stiff ODE system that arises from a system of partial
differential equations. The PDE system is a six-species food web population
model, with predator-prey interaction and diffusion on the unit square in
two dimensions. Given the dependent variable vector of species concentrations
$c = [c_1, c_2,..., c_{ns}]^T$, where $ns$ is the number of species and $np$
is the number of predators and of prey, then
the PDEs can be written as
\begin{equation}\label{kinwebspde}
  d(i) \cdot \left( \frac{\partial^2 c_i}{\partial x^2} + \frac{\partial^2 c_i}{\partial y^2} \right) + f_i(x,y,c) = 0
  \quad (i=1,...,ns)~,
\end{equation}
where the subscripts $i$ are used to distinguish the species, and where
\begin{equation}\label{e:kinwebsfterm}
f_i(x,y,c) = c_i \cdot \left(b(i) + \sum_{j=1}^{ns} a(i,j) \cdot c_j \right)
\end{equation}
and the coefficients are given by
\begin{equation}\label{e:kinwebs:r}
\begin{split}
  a(i,j)& = -1 \quad (i = 1,...,ns) \\
  a(i,j)& = -0.5\cdot 10^{-6} \quad (i \leq np , j > np) \\
  a(i,j)& = 10000  \quad (i > np , j \leq np) \\
  b(i)& = 1 + \alpha x y \quad (i \leq np) \\
  b(i)& = -1 - \alpha x y \quad (i > np) \\
  d(i)& = 1 \quad (i \leq np) \\
  d(i)& = 0.5 \quad (i > np)
\end{split}
\end{equation}
The spatial domain is $0 \leq x \leq 1,\;0 \leq y \leq 1$ (unit square).

The boundary conditions are normal derivative equal to zero, and the initial
guess is constant in both $x$ and $y$. For this example, the equations
(\ref{kinwebspde}) are discretized spatially with standard central finite
differences on a $8 \times 8$ mesh with $ns = 6$, giving a system of size $384$.

Among the initial \id{\#include} lines in this case are lines to
include \id{kinspgmr.h} and \id{sundialsmath.h}.  The first contains
constants and function prototypes associated with the {\spgmr} method.
The inclusion of \id{sundialsmath.h} is done to access the \id{MAX} and
\id{ABS} macros, and the \id{RSqrt} function to compute the square root
of a \id{realtype} number.

The \id{main} program calls \id{KINCreate} and then calls \id{KINMalloc} with the
name of the user-supplied system function and dependent variable vector as
arguments. It calls  \id{KINSpgmr} to specify the {\kinspgmr} linear solver, and
passes a  value of $15$ as the maximum Krylov subspace dimension.
Next, user-supplied preconditioner setup and solve functions, \id{Precond} and
\id{PSolveb}, are specified through calls to \id{KINSpgmrSetPrecSetupFn} and
\id{KINSpgmrSetPrecSolveFn}, respectively. The \id{data} pointer passed to
\id{KINSpgmrSetPrecData} is passed to \id{Precond} and \id{PSolveb} whenever
these are called. See \S\ref{sss:lin_solv_init} and \S\ref{ss:optional_input} in
the user guide for details on these calls.

Then \id{KINSol} is called, the return value is tested for error conditions, and
the approximate solution vector is printed via a call to \id{PrintOutput}.
After that, \id{PrintFinalStats} is called to get and print final statistics, and
memory is freed by calls to \id{N\_VDestroy}, \id{FreeUserData} and \id{KINFree}.
The statistics printed are the total numbers of nonlinear iterations (\id{nni}),
of \id{f} evaluations (excluding those for $Jv$ product evaluations) (\id{nfe}),
of \id{f} evaluations for $Jv$ evaluations (\id{nfeSG}), of linear (Krylov)
iterations (\id{nli}), of preconditioner evaluations (\id{npe}), and of
preconditioner solves (\id{nps}). All of these optional outputs and others are
described in \S\ref{ss:optional_output}.

Mathematically, the dependent variable has three dimensions: species
number, $x$ mesh point, and $y$ mesh point.  But in {\nvecs}, a vector of
type \id{N\_Vector} works with a one-dimensional contiguous array of
data components. The macro \id{IJ_Vptr} isolates the translation from
three dimensions to one. Its use results in clearer code and makes it
easy to change the underlying layout of the three-dimensional data. 
Here the problem size is $384$, so we use the \id{NV\_DATA\_S} macro
for efficient \id{N\_Vector} access. The \id{NV\_DATA\_S} macro gives
a pointer to the first component of an \id{N\_Vector} which we pass to
the \id{IJKth} macro to do an \id{N\_Vector} access.

The preconditioner used here is the block-diagonal part of the true Newton
matrix.  It is generated and factored in the \id{Precond} routine and
backsolved in the \id{PSolve} routine.   Its diagonal blocks are $2 \times 2$
matrices that include the interaction Jacobian elements and the diagonal
contribution of the diffusion Jacobian elements.  The block-diagonal part of
the Jacobian itself, $J_{bd}$, is saved in separate storage each time it is
generated, on calls to \id{Precond} with \id{jok}\id{ == FALSE}.
On calls with \id{jok}\id{ == TRUE}, signifying that saved Jacobian data
can be reused, the preconditioner $P = I - \gamma J_{bd}$ is formed from the
saved matrix $J_{bd}$ and factored.  (A call to \id{Precond} with
\id{jok}\id{ == TRUE} can only occur after a prior call with
\id{jok}\id{ == FALSE}.)  The \id{Precond} routine must also set the value
of \id{jcur}, i.e. \id{*jcurPtr}, to \id{TRUE} when $J_{bd}$ is re-evaluated,
and \id{FALSE} otherwise, to inform {\cvspgmr} of the status of Jacobian data.
See \S\ref{ss:precondFn} and \S\ref{ss:psolveFn} for detailed descriptions
of these preconditioner functions.

We need to take a brief detour to explain one last important aspect of
the \id{cvkx.c} program.  The generic {\dense} solver contains two
sets of functions: one for ``large'' matrices and one for ``small''
matrices.  The large dense functions work with the type \id{DenseMat},
while the small dense functions work with \id{realtype **} as the
underlying dense matrix types.  The {\cvdense} linear solver uses the
type \id{DenseMat} for the $N \times N$ dense Jacobian and Newton
matrices, and calls the large matrix functions.  But to avoid the
extra layer of function calls, \id{cvkx.c} uses the small dense
functions for all operations on the $2 \times 2$ preconditioner blocks.  
Thus it includes \id{smalldense.h}, and calls the small dense matrix
functions \id{denalloc}, \id{dencopy}, \id{denscale}, \id{denaddI}, 
\id{denfree}, \id{denfreepiv}, \id{gefa}, and \id{gesl}.  The macro
\id{IJth} defined near the top of the file is used to access
individual elements in each preconditioner block, numbered from $1$.
The small dense functions are available for {\cvode} user programs
generally, and are documented in \S\ref{ss:dense}.

In addition to the functions called by {\cvode}, \id{cvkx.c} includes
definitions of several private functions.  These are: \id{AllocUserData}
to allocate space for $J_{bd}$, $P$, and the pivot arrays; \id{InitUserData}
to load problem constants in the \id{data} block; \id{FreeUserData} to free
that block; \id{SetInitialProfiles} to load the initial values in \id{y}; 
\id{PrintOutput} to retreive and print selected solution values and
statistics; \id{PrintFinalStats} to print statistics; and \id{check\_flag}
to check return values for error conditions.

The output generated by \id{kinwebs.c} is shown below.  Note that the
number of preconditioner evaluations, \id{npe}, is much smaller than
the number of preconditioner setups, \id{nsetups}, as a result of the
Jacobian re-use scheme.

%%
\vspace{0.1in}
\VerbatimInput[frame=single,framesep=0.1in,label={\tt kinwebs} sample output,
  fontsize=\small]{../examples_ser/kinwebs.out}
%%

%-------------------------------------------------------------------------------
