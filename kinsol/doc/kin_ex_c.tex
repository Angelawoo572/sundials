%===================================================================================
\section{C example problems}\label{s:ex_c}
%===================================================================================

\subsection{A serial example: kinkryx}\label{ss:kinkryx}

We give here an example that illustrates the use of {\kinsol} with the Krylov
method {\spgmr}, in the {\kinspgmr} module, as the linear system solver.
The source file, \id{kinkryx.c}, is listed in Appendix \ref{s:kinkryx_c}.

This program solves a nonlinear system that arises from a discretized system of partial
differential equations. The PDE system is a six-species food web population
model, with predator-prey interaction and diffusion on the unit square in
two dimensions. Given the dependent variable vector of species concentrations
$c = [c_1, c_2,..., c_{n_s}]^T$, where $n_s = 2 n_p$ is the number of species 
and $n_p$ is the number of predators and of prey, then
the PDEs can be written as
\begin{equation}\label{e:kinkryx_pde}
  d_i \cdot \left( \frac{\partial^2 c_i}{\partial x^2} + 
    \frac{\partial^2 c_i}{\partial y^2} \right) + f_i(x,y,c) = 0
  \quad (i=1,...,n_s) \, ,
\end{equation}
where the subscripts $i$ are used to distinguish the species, and where
\begin{equation}\label{e:kinkryx_fterm}
f_i(x,y,c) = c_i \cdot \left(b_i + \sum_{j=1}^{n_s} a_{i,j} \cdot c_j \right) \, .
\end{equation}
The problem coefficients are given by
\begin{equation*}
  a_{ij} = 
  \begin{cases}
    -1                 & i=j \\
    -0.5 \cdot 10^{-6} & i \leq n_p , ~ j > n_p  \\
    10^4               & i > n_p , ~ j \leq n_p  \\
    0                  & \mbox{all other } \, ,
  \end{cases}
\end{equation*}
%%
\begin{equation*}
  b_i = b_i(x,y) = 
  \begin{cases}
    1 + \alpha xy   & i \leq n_p  \\
    -1 - \alpha xy   & i > n_p \, ,
  \end{cases}
\end{equation*}
and
%%
\begin{equation*}
  d_i = 
  \begin{cases}
    1 & i \leq n_p  \\
    0.5 & i > n_p  \, .
  \end{cases}
\end{equation*}
The spatial domain is the unit square $(x,y) \in [0,1] \times [0,1]$.

Homogeneous Neumann boundary conditions are imposed and the initial
guess is constant in both $x$ and $y$. For this example, the equations
(\ref{e:kinkryx_pde}) are discretized spatially with standard central finite
differences on a $8 \times 8$ mesh with $n_s = 6$, giving a system of size $384$.

Among the initial \id{\#include} lines in this case are lines to
include \id{kinso\_spgmr.h} and \id{sundials\_math.h}.  The first contains
constants and function prototypes associated with the {\spgmr} method.
The inclusion of \id{sundials\_math.h} is done to access the \id{MAX} and
\id{ABS} macros, and the \id{RSqrt} function to compute the square root
of a \id{realtype} number.

The \id{main} program calls \id{KINCreate} and then calls \id{KINMalloc} with the
name of the user-supplied system function \id{func} and solution vector as
arguments.  The \id{main} program then calls a number of \id{KINSet*}
routines to notify {\kinsol} of the function data pointer, the
positivity constraints on the solution, and convergence tolerances on
the system function and step size.
It calls  \id{KINSpgmr} (see \ugref{sss:lin_solv_init}) to specify the {\kinspgmr} 
linear solver, and passes a  value of $15$ as the maximum Krylov subspace dimension,
\id{maxl}.  Next, a maximum value of \id{maxlrst} $=2$ restarts is imposed and
the user-supplied preconditioner setup and solve functions, \id{PrecSetupBD} and
\id{PrecSolveBD}, and the pointer to user data are specified through a call to
\id{KINSpilsSetPreconditioner} (see \ugref{ss:optional_input}).
The \id{data} pointer passed to \id{KINSpilsSetPreconditioner} is passed to \id{PrecSetupBD} 
and \id{PrecSolveBD} whenever these are called. 

Next, \id{KINSol} is called, the return value is tested for error conditions, and
the approximate solution vector is printed via a call to \id{PrintOutput}.
After that, \id{PrintFinalStats} is called to get and print final statistics, and
memory is freed by calls to \id{N\_VDestroy\_Serial}, \id{FreeUserData} and \id{KINFree}.
The statistics printed are the total numbers of nonlinear iterations (\id{nni}),
of \id{func} evaluations (excluding those for $Jv$ product evaluations) (\id{nfe}),
of \id{func} evaluations for $Jv$ evaluations (\id{nfeSG}), of linear (Krylov)
iterations (\id{nli}), of preconditioner evaluations (\id{npe}), and of
preconditioner solves (\id{nps}). All of these optional outputs and others are
described in \ugref{ss:optional_output}.

Mathematically, the dependent variable has three dimensions: species
number, $x$ mesh point, and $y$ mesh point.  But in {\nvecs}, a vector of
type \id{N\_Vector} works with a one-dimensional contiguous array of
data components. The macro \id{IJ\_Vptr} isolates the translation from
three dimensions to one. Its use results in clearer code and makes it
easy to change the underlying layout of the three-dimensional data. 
Here the problem size is $384$, so we use the \id{NV\_DATA\_S} macro
for efficient \id{N\_Vector} access. The \id{NV\_DATA\_S} macro gives
a pointer to the first component of a serial \id{N\_Vector} which is then
passed to the \id{IJ\_Vptr} macro.

The preconditioner used here is the block-diagonal part of the true Newton
matrix and is based only on the partial derivatives of the interaction terms $f$
in (\ref{e:kinkryx_fterm}) and hence its  diagonal blocks are $n_s \times n_s$ matrices
($n_s = 6$).
It is generated and factored in the \id{PrecSetupBD} routine and
backsolved in the \id{PrecSolveBD} routine.  
See \ugref{ss:precondFn} for detailed descriptions
of these preconditioner functions.

The program \id{kinkryx.c} uses the ``small'' dense functions for all operations 
on the $6 \times 6$ preconditioner blocks.  
Thus it includes \id{sundials\_smalldense.h}, and calls the small dense matrix
functions \id{denalloc}, \id{denallocpiv}, 
\id{denfree}, \id{denfreepiv}, \id{gefa}, and \id{gesl}.
The small dense functions are generally available for {\kinsol} user programs
(for more information, see \ugref{ss:dense} or the comments in the header file
\id{sundials\_smalldense.h}).

In addition to the functions called by {\kinsol}, \id{kinkryx.c} includes
definitions of several private functions.  These are: \id{AllocUserData}
to allocate space for $P$ and the pivot arrays; \id{InitUserData}
to load problem constants in the \id{data} block; \id{FreeUserData} to free
that block; \id{SetInitialProfiles} to load the initial values in \id{cc}; 
\id{PrintOutput} to retreive and print selected solution values;
\id{PrintFinalStats} to print statistics; and \id{check\_flag}
to check return values for error conditions.

The output generated by \id{kinkryx} is shown below.  Note that the
solution involved 7 Newton iterations, with an average of about 33
Krylov iterations per Newton iteration.

\includeOutput{kinkryx}{../examples_ser/kinkryx.out}

%-----------------------------------------------------------------------------------

\subsection{A parallel example: kinkryx\_bbd\_p}\label{ss:kinkryx_bbd_p}

In this example, \id{kinkryx\_bbd\_p}, we solve the same problem as with \id{kinkryx}
above, but in parallel, and instead of supplying the preconditioner we use the
{\kinbbdpre} module.  The source is given in Appendix \ref{s:kinkryx_bbd_p_c}.

In this case, we think of the parallel {\mpi} processes as
being laid out in a rectangle, and each process being assigned a
subgrid of size \id{MXSUB}$\times$\id{MYSUB} of the $x-y$ grid. If
there are \id{NPEX} processes in the $x$ direction and \id{NPEY}
processes in the $y$ direction, then the overall grid size is
\id{MX}$\times$\id{MY} with \id{MX}$=$\id{NPEX}$\times$\id{MXSUB} and
\id{MY}$=$\id{NPEY}$\times$\id{MYSUB}, and the size of the nonlinear system is
\id{NUM\_SPECIES}$\cdot$\id{MX}$\cdot$\id{MY}.  

The evaluation of the nonlinear system function is performed in \id{func}.
In this parallel setting, the processes first communicate the subgrid
boundary data and then compute the local components of the nonlinears system
function. The {\mpi} communication is isolated in the private function \id{ccomm}
(which in turn calls \id{BRecvPost}, \id{BSend}, and \id{BRecvWait}) and the 
subgrid boundary data received from neighboring processes is loaded into the
work array \id{cext}. The computation of the nonlinear system function is done
in \id{func\_local} which starts by copying the local segment of the \id{cc}
vector into \id{cext} and then by imposing the boundary conditions by copying the
first interior mesh line from \id{cc} into \id{cext}. After this, the nonlinear
system function is evaluated by using central finite-difference approximations
using the data in \id{cext} exclusively.

{\kinbbdpre} uses a band-block-diagonal preconditioner, generated by difference
quotients.  The upper and lower half-bandwidths of the Jacobian block generated
on each process are both equal to $2 \cdot n_s - 1$, and that is the value
passeded as \id{mudq} and \id{mldq} in the call to \id{KINBBDPrecAlloc}.
These values are much less than the true half-bandwidths of the Jacobian blocks,
which are $n_s \cdot$ \id{MXSUB}.  However, an even narrower band matrix
is retained as the preconditioner, with half-bandwidths equal to $n_s$, and this
is the value passed to \id{KINBBDPrecAlloc} for \id{mu} and \id{ml}.

The function \id{func\_local} is also passed as the \id{gloc} argument to 
\id{KINBBDPrecAlloc}. Since all communication needed for the evaluation of the
local aproximation of $f$ used in building the band-block-diagonal preconditioner
is already done for the evaluation of $f$ in \id{func}, a \id{NULL} pointer is
passed as the \id{gcomm} argument to \id{KINBBDPrecAlloc}.

The \id{main} program resembles closely that of the \id{kinkryx} example, with
particularization arising from the use of the parallel {\mpi} {\nvecp} module.
It begins by initializing {\mpi} and obtaining the total number of processes and 
the rank of the local process. The local length of the solution vector is then 
computed as \id{NUM\_SPECIES}$\cdot$\id{MXSUB}$\cdot$\id{MYSUB}.
Distributed vectors are created by calling the constructor defined in {\nvecp}
with the {\mpi} communicator and the local and global problem sizes as arguments.
All output is performed only from the process with id equal to $0$.
Finally, after all memory deallocation, the {\mpi} environment is terminated by
calling \id{MPI\_Finalize}.

The output generated by \id{kinkryx\_bbd\_p} is shown below.  Note that 9 Newton
iterations were required, with an average of about 51.6 Krylov iterations
per Newton iteration.

\includeOutput{kinkryx\_bbd\_p}{../examples_par/kinkryx_bbd_p.out}


