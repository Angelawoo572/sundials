% This is a shared SUNDIALS TEX file with description of
% the CUDA nvector implementation
%
The {\nveccuda} module is an experimental implementation of {\nvector} in the {\cuda} language. 
The module allows for {\sundials} vector kernels to run on GPU devices. It is intended for users 
who are already familiar with {\cuda} and GPU programming. Building this vector 
module requires a CUDA compiler and, by extension, a C++ compiler. The class \id{Vector} 
in namespace \id{suncudavec} manages vector data layout: 
\begin{verbatim} 
template <class T, class I>
class Vector {
  I size_;
  I mem_size_;
  T* h_vec_;
  T* d_vec_;
  StreamPartitioning<T, I>* partStream_;
  ReducePartitioning<T, I>* partReduce_;
  bool ownPartitioning_;
  
  ...
};
\end{verbatim}

The class members are vector size (length), size of the vector data memory block, pointers
to vector data on the host and the device, pointers to classes \id{StreamPartitioning}
and \id{ReducePartitioning}, which handle thread partitioning for streaming and 
reduction vector kernels, respectively, and a boolean flag that signals if the
vector owns the thread partitioning. The class \id{Vector} inherits from the empty structure
\begin{verbatim} 
struct _N_VectorContent_Cuda {
};
\end{verbatim}
to interface the C++ class with the {\nvector} C code. When instantiated, the class
\id{Vector} will allocate memory on both the host and the device. Due to the rapid
progress of {\cuda} development, we expect that the \id{suncudavec::Vector}
class will change frequently in future {\sundials} releases. The code is
structured so that it can tolerate significant changes in the 
\id{suncudavec::Vector} class without requiring changes to the user API.

%%
%%--------------------------------------------

The header file to be included when using this module is \id{nvector\_cuda.h}.
Unlike other native {\sundials} vector types, {\nveccuda} does not provide macros 
to access its member variables.
Note that {\nveccuda} requires {\sundials} to be built with {\mpi} support.


%%
%%--------------------------------------------
%%
The {\nveccuda} module defines implementations of all vector operations listed 
in Table \ref{t:nvecops}, except for \verb|N_VGetArrayPointer| and 
\verb|N_VSetArrayPointer|. 
As such, this vector cannot be used with {\sundials} Fortran interfaces,
nor with {\sundials} direct solvers and preconditioners. This support
will be added in subsequent {\sundials} releases. 
The {\nveccuda} module provides separate functions to access data on the host
and on the device. It also provides methods for copying from the host to 
the device and vice versa. Usage examples of {\nveccuda} are provided in
some example programs for {\cvode} \cite{cvode_ex}.

The names of vector operations are obtained from those in 
Table \ref{t:nvecops} by appending the suffix \id{\_Cuda} (e.g. \id{N\_VDestroy\_Cuda}).
The module {\nveccuda}  provides the following additional user-callable routines:
%%
%%
\begin{itemize}

  
%%--------------------------------------

\item \ID{N\_VNew\_Cuda}
 
  This function creates and allocates memory for a {\cuda} \id{N\_Vector}.
  The memory is allocated on both host and device. Its only argument is the 
  vector length. 

\begin{verbatim}
N_Vector N_VNew_Cuda(sunindextype vec_length);
\end{verbatim}

  
%%--------------------------------------

\item \ID{N\_VNewEmpty\_Cuda}
 
  This function creates a new {\nvector} wrapper with the pointer to
  the wrapped {\cuda} vector set to (\id{NULL}). It is used by the 
  \id{N\_VNew\_Cuda}, \id{N\_VMake\_Cuda}, and \id{N\_VClone\_Cuda} 
  implementations. 

\begin{verbatim}
N_Vector N_VNewEmpty_Cuda(sunindextype vec_length);
\end{verbatim}

  
%%--------------------------------------

\item \ID{N\_VMake\_Cuda}
  
  This function creates and allocates memory for an {\nveccuda}
  wrapper around a user-provided \id{suncudavec::Vector} class. 
  Its only argument is of type \id{N\_VectorContent\_Cuda}, which
  is the pointer to the class.

\begin{verbatim}
N_Vector N_VMake_Cuda(N_VectorContent_Cuda c);
\end{verbatim}

%%--------------------------------------


\item \ID{N\_VCloneVectorArray\_Cuda}
 
  This function creates (by cloning) an array of \id{count} {\nveccuda} vectors.
 
\begin{verbatim}
N_Vector *N_VCloneVectorArray_Cuda(int count, N_Vector w);
\end{verbatim}

%%--------------------------------------

\item \ID{N\_VCloneVectorArrayEmpty\_Cuda}
 
  This function creates (by cloning) an array of \id{count} {\nveccuda} vectors,
  each with pointers to {\cuda} vectors set to (\id{NULL}).
 
\begin{verbatim}
N_Vector *N_VCloneEmptyVectorArray_Cuda(int count, N_Vector w);
\end{verbatim}

%%--------------------------------------

\item \ID{N\_VDestroyVectorArray\_Cuda}
 
 This function frees memory allocated for the array of \id{count} variables of
 type \id{N\_Vector} created with \id{N\_VCloneVectorArray\_Cuda} or with
 \id{N\_VCloneVectorArrayEmpty\_Cuda}.
 

 \verb|void N_VDestroyVectorArray_Cuda(N_Vector *vs, int count);|

%%--------------------------------------

\item \ID{N\_VGetLength\_Cuda}
 
 This function returns the length of the vector.

 \verb|sunindextype N_VGetLength_Cuda(N_Vector v);|

%%--------------------------------------

\item \ID{N\_VGetHostArrayPointer\_Cuda}
 
 This function returns a pointer to the vector data on the host.

 \verb|realtype *N_VGetHostArrayPointer_Cuda(N_Vector v);|


%%--------------------------------------

\item \ID{N\_VGetDeviceArrayPointer\_Cuda}
 
 This function returns a pointer to the vector data on the device.

 \verb|realtype *N_VGetDeviceArrayPointer_Cuda(N_Vector v);|


%%--------------------------------------

\item \ID{N\_VCopyToDevice\_Cuda}
 
 This function copies host vector data to the device.

 \verb|realtype *N_VCopyToDevice_Cuda(N_Vector v);|


%%--------------------------------------

\item \ID{N\_VCopyFromDevice\_Cuda}
 
 This function copies vector data from the device to the host.

 \verb|realtype *N_VCopyFromDevice_Cuda(N_Vector v);|


%%--------------------------------------

\item \ID{N\_VPrint\_Cuda}
  
  This function prints the content of a wrapped {\cuda} vector to stdout.
 
    
  \verb|void N_VPrint_Cuda(N_Vector v);|


\end{itemize}
%%
%%------------------------------------
%%
\paragraph{\bf Notes} 
           
\begin{itemize}
                                        
\item
  When there is a need to access components of an \id{N\_Vector\_Cuda}, \id{v}, 
  it is recommeded to use functions \id{N\_VGetDeviceArrayPointer\_Cuda} or 
  \id{N\_VGetHostArrayPointer\_Cuda}.        
                                                               
% \item
%   {\warn}Unlike in other {\nvector} implementations, vector data will always be
%   deleted when invoking \id{N\_VDestroy\_Cuda} and \id{N\_VDestroyVectorArray\_Cuda},
%   even when the vector is created using \id{N\_VMake\_Cuda}. It is user's responsibility
%   to track memory allocations and deletions when using \id{N\_VMake\_Cuda}.

\item
  {\warn}To maximize efficiency, vector operations in the {\nveccuda} implementation
  that have more than one \id{N\_Vector} argument do not check for
  consistent internal representations of these vectors. It is the user's 
  responsibility to ensure that such routines are called with \id{N\_Vector}
  arguments that were all created with the same internal representations.

\end{itemize}

